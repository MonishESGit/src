[Home](https://lualure.github.io/info/index) |
[Why](https://lualure.github.io/info/WHY) |
[What](https://lualure.github.io/info/WHAT) |
[Guide](https://lualure.github.io/info/GUIDE) |
[Licenses](LICENSE.md) |
<img align=top src="https://img.shields.io/badge/tests-passed-green?style=for-the-badge&logo=TestCafe">

#36B6E5

<img align=right src="https://avatars6.githubusercontent.com/u/30064709?v=4&s=200">

# LUA LURE

_tim@menzies.us_    
_August '17_ 

LURE is a set of minimal data mining tools designed with the goal of letting their students "roll their sleeves up" to muck around inside data miners.

The code is written in LUA since:

- LUA is FUN!
- LUA is cool; think "Scheme", then throw away all the brackets;
- LUA programs are not resource intensive;
- LUA is  very portable to different platforms
- LUA code are very succinct and hence easily modifiable;
- LUA code is quite readable so for students who not know how to write LUA code; I can use LURE as a kind of executable specification; e.g. write this code in your favorite language).
- There are some interesting LUA data mining tool likes e.g. TORCH.

This code offers _baseline_ implementations of a set of 
[software science operators](https://lualure.github.io/info/WHAT.html) which, I say, are needed for data science. But you should be very critical of the technical choices I made in that implementation. What simplifications did I make? What better technologies should I use? What did I overlook? And (here's the trap) if you think you can handle the above in (e.g.) TensorFlow or Torch or using 100 other methods, I would lean forward and say "yes? really? show me how".

